{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d80255",
   "metadata": {},
   "source": [
    "# Scholarship Data Upload to MySQL Database\n",
    "\n",
    "This notebook uploads the scraped scholarship data from CSV files to a MySQL database. It includes:\n",
    "- Date cleaning and formatting\n",
    "- Database connection and table creation\n",
    "- Data validation and deduplication\n",
    "- Progress tracking and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8104274",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f143b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684a5431",
   "metadata": {},
   "source": [
    "## 2. Date Cleaning Function\n",
    "\n",
    "This function converts various date string formats to MySQL date format (YYYY-MM-DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(date_str):\n",
    "    \"\"\"Convert various date string formats to MySQL date format YYYY-MM-DD\"\"\"\n",
    "    if pd.isna(date_str) or not date_str or date_str.strip() == \"\":\n",
    "        return None\n",
    "        \n",
    "    # Remove any \"Apply Now\" or \"Official Link\" text\n",
    "    date_str = re.sub(r'Apply Now.*|Official Link.*', '', date_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Try to extract date patterns\n",
    "    patterns = [\n",
    "        # Day Month Year formats\n",
    "        r'(\\d{1,2})(?:st|nd|rd|th)?\\s*(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s*,?\\s*(\\d{4})',\n",
    "        r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s*(\\d{1,2})(?:st|nd|rd|th)?\\s*,?\\s*(\\d{4})',\n",
    "        \n",
    "        # Year Month Day formats\n",
    "        r'(\\d{4})[/-](\\d{1,2})[/-](\\d{1,2})',\n",
    "        r'(\\d{4})\\s*(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s*(\\d{1,2})',\n",
    "        \n",
    "        # Month Year formats (assuming day 1)\n",
    "        r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s*(\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    # Month name to number mapping\n",
    "    month_map = {\n",
    "        'january': 1, 'february': 2, 'march': 3, 'april': 4,\n",
    "        'may': 5, 'june': 6, 'july': 7, 'august': 8,\n",
    "        'september': 9, 'october': 10, 'november': 11, 'december': 12\n",
    "    }\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, date_str, re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                # For standard date formats, try parsing directly\n",
    "                try:\n",
    "                    date_obj = datetime.strptime(match.group(0), \"%d %B %Y\")\n",
    "                    return date_obj.strftime(\"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    date_obj = datetime.strptime(match.group(0), \"%B %d %Y\")\n",
    "                    return date_obj.strftime(\"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    date_obj = datetime.strptime(match.group(0), \"%B %d, %Y\")\n",
    "                    return date_obj.strftime(\"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                    \n",
    "                # For Year-Month-Day format\n",
    "                if re.match(r'\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}', match.group(0)):\n",
    "                    date_parts = re.split(r'[/-]', match.group(0))\n",
    "                    return f\"{date_parts[0]}-{int(date_parts[1]):02d}-{int(date_parts[2]):02d}\"\n",
    "                \n",
    "                # For \"Month Year\" format (use 1st day of month)\n",
    "                month_year_match = re.match(r'(\\w+)\\s+(\\d{4})', match.group(0), re.IGNORECASE)\n",
    "                if month_year_match:\n",
    "                    month_name = month_year_match.group(1).lower()\n",
    "                    year = month_year_match.group(2)\n",
    "                    if month_name in month_map:\n",
    "                        return f\"{year}-{month_map[month_name]:02d}-01\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Date parsing error for '{date_str}': {str(e)}\")\n",
    "                \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2cd76",
   "metadata": {},
   "source": [
    "## 3. Database Functions\n",
    "\n",
    "Functions for creating tables and checking for existing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(cursor):\n",
    "    \"\"\"Create scholarships table if it doesn't exist\"\"\"\n",
    "    # Drop existing table\n",
    "    drop_table_sql = \"DROP TABLE IF EXISTS scholarships;\"\n",
    "    cursor.execute(drop_table_sql)\n",
    "    \n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE scholarships (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        title VARCHAR(500),\n",
    "        description TEXT,\n",
    "        link VARCHAR(500),\n",
    "        official_link VARCHAR(500),\n",
    "        deadline DATE,\n",
    "        eligibility TEXT,\n",
    "        host_country VARCHAR(100),\n",
    "        host_university VARCHAR(200),\n",
    "        program_duration VARCHAR(200),\n",
    "        degree_offered VARCHAR(200),\n",
    "        region VARCHAR(50),\n",
    "        post_at DATE,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n",
    "        INDEX (title(255)),\n",
    "        INDEX (link(255)),\n",
    "        INDEX (region),\n",
    "        INDEX (post_at)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_sql)\n",
    "\n",
    "def scholarship_exists(cursor, title, link):\n",
    "    \"\"\"Check if a scholarship already exists in the database\"\"\"\n",
    "    check_sql = \"\"\"\n",
    "    SELECT COUNT(*) FROM scholarships \n",
    "    WHERE title = %s OR link = %s\n",
    "    \"\"\"\n",
    "    cursor.execute(check_sql, (title, link))\n",
    "    count = cursor.fetchone()[0]\n",
    "    return count > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24eb69b",
   "metadata": {},
   "source": [
    "## 4. CSV Processing Function\n",
    "\n",
    "Function to process CSV files and insert data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0db449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(cursor, file_path):\n",
    "    \"\"\"Process a single CSV file and insert data into database\"\"\"\n",
    "    print(f\"\\nüìÑ Processing: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # Track statistics for this file\n",
    "    total_rows = 0\n",
    "    skipped_rows = 0\n",
    "    inserted_rows = 0\n",
    "    error_rows = 0\n",
    "    \n",
    "    try:\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Clean and prepare data\n",
    "        for _, row in df.iterrows():\n",
    "            total_rows += 1\n",
    "            \n",
    "            try:\n",
    "                # Skip rows with empty titles\n",
    "                if pd.isna(row['Title']) or row['Title'].strip() == \"\":\n",
    "                    print(f\"‚ö†Ô∏è Skipped row {total_rows} (no title)\")\n",
    "                    skipped_rows += 1\n",
    "                    continue\n",
    "                \n",
    "                # Check if scholarship already exists\n",
    "                if scholarship_exists(cursor, row['Title'], row['Link']):\n",
    "                    print(f\"‚è≠Ô∏è Skipped (already exists): {row['Title'][:50]}...\")\n",
    "                    skipped_rows += 1\n",
    "                    continue\n",
    "\n",
    "                # Clean deadline date\n",
    "                deadline = clean_date(row.get('Deadline', None))\n",
    "                \n",
    "                # Determine post date based on deadline rules\n",
    "                post_at = None\n",
    "                try:\n",
    "                    if deadline:\n",
    "                        deadline_date = datetime.strptime(deadline, \"%Y-%m-%d\")\n",
    "                        today = datetime.today()\n",
    "                        \n",
    "                        if deadline_date < today:\n",
    "                            # Deadline passed ‚Üí post_at = 30 days before deadline\n",
    "                            post_at = (deadline_date - pd.Timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "                            print(f\"üìÜ Expired deadline. Set post_at to 30 days before: {post_at}\")\n",
    "                        else:\n",
    "                            # Deadline is future ‚Üí post_at = scrape date (today)\n",
    "                            post_at = today.strftime(\"%Y-%m-%d\")\n",
    "                            print(f\"üìÜ Upcoming deadline. Set post_at to today's date: {post_at}\")\n",
    "                    else:\n",
    "                        post_at = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "                        print(f\"üìÜ No deadline. Default post_at to today: {post_at}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to calculate post_at: {str(e)}\")\n",
    "                    post_at = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                # Get region from data or from filename\n",
    "                region = row.get('Region', None)\n",
    "                if region is None or pd.isna(region):\n",
    "                    # Extract region from filename\n",
    "                    filename = os.path.basename(file_path)\n",
    "                    match = re.search(r'scholarships-(\\w+)', filename)\n",
    "                    if match:\n",
    "                        region = match.group(1).replace('-', ' ').title()\n",
    "                \n",
    "                # Insert data\n",
    "                insert_sql = \"\"\"\n",
    "                INSERT INTO scholarships (\n",
    "                    title, description, link, official_link, deadline, \n",
    "                    eligibility, host_country, host_university, \n",
    "                    program_duration, degree_offered, region, post_at\n",
    "                ) VALUES (\n",
    "                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "                )\n",
    "                \"\"\"\n",
    "                \n",
    "                data = (\n",
    "                    row['Title'],\n",
    "                    row.get('Description', None),\n",
    "                    row.get('Link', None),\n",
    "                    row.get('Official Link', None),\n",
    "                    deadline,\n",
    "                    row.get('Eligibility', None),\n",
    "                    row.get('Host Country', None),\n",
    "                    row.get('Host University', None),\n",
    "                    row.get('Program Duration', None),\n",
    "                    row.get('Degree Offered', None),\n",
    "                    region,\n",
    "                    post_at\n",
    "                )\n",
    "                \n",
    "                cursor.execute(insert_sql, data)\n",
    "                print(f\"‚úÖ Inserted: {row['Title'][:50]}...\")\n",
    "                inserted_rows += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing row {total_rows}: {str(e)}\")\n",
    "                error_rows += 1\n",
    "        \n",
    "        return {\n",
    "            'total': total_rows,\n",
    "            'skipped': skipped_rows,\n",
    "            'inserted': inserted_rows,\n",
    "            'errors': error_rows\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing file {file_path}: {str(e)}\")\n",
    "        return {\n",
    "            'total': 0,\n",
    "            'skipped': 0,\n",
    "            'inserted': 0,\n",
    "            'errors': 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884d5d4",
   "metadata": {},
   "source": [
    "## 5. Main Execution\n",
    "\n",
    "Connect to the database and process all CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b7e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "db_config = {\n",
    "    'host': '35.174.114.119', \n",
    "    'user': 'root',\n",
    "    'password': '',  # Update this with your MySQL root password if you have one\n",
    "    'database': 'mydb'\n",
    "}\n",
    "\n",
    "# Overall statistics\n",
    "stats = {\n",
    "    'total_files': 0,\n",
    "    'total_rows': 0,\n",
    "    'total_skipped': 0,\n",
    "    'total_inserted': 0,\n",
    "    'total_errors': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Connect to MySQL\n",
    "    print(\"üîå Connecting to MySQL database...\")\n",
    "    conn = mysql.connector.connect(**db_config)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table if it doesn't exist\n",
    "    print(\"üèóÔ∏è Setting up database table...\")\n",
    "    create_table(cursor)\n",
    "\n",
    "    # Find all CSV files to process\n",
    "    data_dir = \"scholarship_data\"  # Default directory from the scraper\n",
    "    all_csv_files = []\n",
    "    \n",
    "    # First check if the combined file exists\n",
    "    master_file = os.path.join(data_dir, \"all_scholarships.csv\")\n",
    "    if os.path.exists(master_file):\n",
    "        print(f\"üì¶ Found master data file: {master_file}\")\n",
    "        all_csv_files = [master_file]\n",
    "    else:\n",
    "        # Otherwise, get all individual region files\n",
    "        csv_pattern = os.path.join(data_dir, \"*.csv\")\n",
    "        all_csv_files = glob.glob(csv_pattern)\n",
    "        \n",
    "        # If no files in the directory, look in current directory\n",
    "        if not all_csv_files:\n",
    "            all_csv_files = glob.glob(\"*.csv\")\n",
    "            \n",
    "    print(f\"üîç Found {len(all_csv_files)} CSV files to process\")\n",
    "    \n",
    "    if not all_csv_files:\n",
    "        print(\"‚ùå No CSV files found! Please run the scraper first.\")\n",
    "    else:\n",
    "        # Process each file\n",
    "        for file_path in all_csv_files:\n",
    "            stats['total_files'] += 1\n",
    "            file_stats = process_csv_file(cursor, file_path)\n",
    "            \n",
    "            # Update overall statistics\n",
    "            stats['total_rows'] += file_stats['total']\n",
    "            stats['total_skipped'] += file_stats['skipped']\n",
    "            stats['total_inserted'] += file_stats['inserted']\n",
    "            stats['total_errors'] += file_stats['errors']\n",
    "            \n",
    "            # Commit after each file to avoid large transactions\n",
    "            conn.commit()\n",
    "\n",
    "        # Final statistics\n",
    "        print(f\"\\nüìä Upload Summary:\")\n",
    "        print(f\"CSV files processed: {stats['total_files']}\")\n",
    "        print(f\"Total scholarships records: {stats['total_rows']}\")\n",
    "        print(f\"New scholarships inserted: {stats['total_inserted']}\")\n",
    "        print(f\"Existing scholarships skipped: {stats['total_skipped']}\")\n",
    "        print(f\"Errors encountered: {stats['total_errors']}\")\n",
    "        print(\"\\nüéâ All data has been processed and uploaded to the database!\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Database Error: {err}\")\n",
    "finally:\n",
    "    if 'conn' in locals() and conn.is_connected():\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
